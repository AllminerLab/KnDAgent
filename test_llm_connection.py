#!/usr/bin/env python3
"""
æµ‹è¯•å¤§æ¨¡å‹è¿æ¥å’Œç”ŸæˆåŠŸèƒ½
"""

import os
import sys
from deploy_deepseek_vllm import DeepSeekVLLMServer

def test_llm_basic():
    """æµ‹è¯•å¤§æ¨¡å‹åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•å¤§æ¨¡å‹åŸºæœ¬åŠŸèƒ½...")
    
    try:
        # åˆ›å»ºæœåŠ¡å™¨å®ä¾‹
        model_path = "./deepseek-llm-7b-chat_new"
        if not os.path.exists(model_path):
            print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
            return False
        
        server = DeepSeekVLLMServer(model_path)
        
        # åˆå§‹åŒ–å¼•æ“
        print("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
        server.initialize_engine()
        print("âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•ç®€å•ç”Ÿæˆ
        test_prompt = "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹åŒ»ç–—çŸ¥è¯†å›¾è°±çš„ä½œç”¨"
        print(f"\næµ‹è¯•æç¤ºè¯: {test_prompt}")
        
        response = server.generate_text(
            prompt=test_prompt,
            max_tokens=100,
            temperature=0.7,
            top_p=0.9
        )
        
        print(f"âœ… ç”ŸæˆæˆåŠŸï¼Œå“åº”é•¿åº¦: {len(response) if response else 0}")
        print(f"å“åº”å†…å®¹: {response}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_llm_medical_prompt():
    """æµ‹è¯•åŒ»ç–—ç›¸å…³çš„æç¤ºè¯"""
    print("\nğŸ¥ æµ‹è¯•åŒ»ç–—ç›¸å…³æç¤ºè¯...")
    
    try:
        server = DeepSeekVLLMServer("./deepseek-llm-7b-chat_new")
        server.initialize_engine()
        
        # æµ‹è¯•åŒ»ç–—æç¤ºè¯
        medical_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ»ç–—çŸ¥è¯†å›¾è°±ä¸“å®¶ã€‚åŸºäºä»¥ä¸‹åŒ»ç–—use caseï¼Œè¯·æ¨èæœ€é€‚åˆçš„çŸ¥è¯†å›¾è°±ç±»å‹ï¼Œå¹¶è¯´æ˜é€‰æ‹©ç†ç”±ã€‚

åŒ»ç–—Use Case: è¯ç‰©ç›¸äº’ä½œç”¨ï¼ˆDDIï¼‰é¢„æµ‹ä»»åŠ¡

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å›ç­”:

## æ¨èçš„çŸ¥è¯†å›¾è°±
**å›¾è°±åç§°**: [æ¨èçš„çŸ¥è¯†å›¾è°±åç§°]

## é€‰æ‹©ç†ç”±
1. **é€‚ç”¨æ€§**: [ä¸ºä»€ä¹ˆè¿™ä¸ªå›¾è°±æœ€é€‚åˆè¯¥use case]
2. **ä¼˜åŠ¿**: [è¯¥å›¾è°±åœ¨æ­¤åœºæ™¯ä¸‹çš„ä¸»è¦ä¼˜åŠ¿]
3. **è¦†ç›–èŒƒå›´**: [è¯¥å›¾è°±å¦‚ä½•è¦†ç›–use caseçš„éœ€æ±‚]
4. **æ•°æ®æ”¯æŒ**: [è¯¥å›¾è°±çš„æ•°æ®æ¥æºå’Œå¯é æ€§]

## å®æ–½å»ºè®®
[ç®€è¦çš„å®æ–½å»ºè®®å’Œæ³¨æ„äº‹é¡¹]"""

        print(f"åŒ»ç–—æç¤ºè¯é•¿åº¦: {len(medical_prompt)}")
        
        response = server.generate_text(
            prompt=medical_prompt,
            max_tokens=500,
            temperature=0.7,
            top_p=0.9
        )
        
        print(f"âœ… åŒ»ç–—æç¤ºè¯ç”ŸæˆæˆåŠŸï¼Œå“åº”é•¿åº¦: {len(response) if response else 0}")
        if response:
            print(f"å“åº”å†…å®¹:\n{response}")
        else:
            print("âŒ å“åº”ä¸ºç©º")
        
        return True
        
    except Exception as e:
        print(f"âŒ åŒ»ç–—æç¤ºè¯æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_chat_mode():
    """æµ‹è¯•èŠå¤©æ¨¡å¼"""
    print("\nğŸ’¬ æµ‹è¯•èŠå¤©æ¨¡å¼...")
    
    try:
        server = DeepSeekVLLMServer("./deepseek-llm-7b-chat_new")
        server.initialize_engine()
        
        messages = [
            {"role": "user", "content": "è¯·æ¨èä¸€ä¸ªé€‚åˆè¯ç‰©ç›¸äº’ä½œç”¨é¢„æµ‹çš„çŸ¥è¯†å›¾è°±"}
        ]
        
        response = server.chat_generate(
            messages=messages,
            max_tokens=300,
            temperature=0.7
        )
        
        print(f"âœ… èŠå¤©æ¨¡å¼æµ‹è¯•æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(response) if response else 0}")
        if response:
            print(f"å“åº”å†…å®¹:\n{response}")
        else:
            print("âŒ å“åº”ä¸ºç©º")
        
        return True
        
    except Exception as e:
        print(f"âŒ èŠå¤©æ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ¤– å¤§æ¨¡å‹è¿æ¥å’Œç”ŸæˆåŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    tests = [
        ("åŸºæœ¬åŠŸèƒ½", test_llm_basic),
        ("åŒ»ç–—æç¤ºè¯", test_llm_medical_prompt),
        ("èŠå¤©æ¨¡å¼", test_chat_mode)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        try:
            if test_func():
                passed += 1
                print(f"âœ… {test_name}æµ‹è¯•é€šè¿‡")
            else:
                print(f"âŒ {test_name}æµ‹è¯•å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name}æµ‹è¯•å¼‚å¸¸: {e}")
    
    # æµ‹è¯•ç»“æœæ±‡æ€»
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*60)
    print(f"æ€»æµ‹è¯•æ•°: {total}")
    print(f"é€šè¿‡æµ‹è¯•: {passed}")
    print(f"å¤±è´¥æµ‹è¯•: {total - passed}")
    print(f"æˆåŠŸç‡: {passed/total*100:.1f}%")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¤§æ¨¡å‹å·¥ä½œæ­£å¸¸")
        print("ç°åœ¨å¯ä»¥é‡æ–°å¯åŠ¨åŒ»ç–—çŸ¥è¯†å›¾è°±æ¨èAgent:")
        print("python start_medical_agent.py")
    else:
        print(f"\nâš ï¸  æœ‰{total-passed}ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¤§æ¨¡å‹é…ç½®")
    
    print("="*60)

if __name__ == "__main__":
    main()
